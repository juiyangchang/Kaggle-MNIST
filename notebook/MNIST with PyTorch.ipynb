{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network With PyTorch\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 42000\n",
      "Number of training pixels: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "\n",
    "n_train = len(train_df)\n",
    "n_pixels = len(train_df.columns) - 1\n",
    "n_class = len(set(train_df['label']))\n",
    "\n",
    "print('Number of training samples: {0}'.format(n_train))\n",
    "print('Number of training pixels: {0}'.format(n_pixels))\n",
    "print('Number of classes: {0}'.format(n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28000\n",
      "Number of test pixels: 784\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "n_test = len(test_df)\n",
    "n_pixels = len(test_df.columns)\n",
    "\n",
    "print('Number of train samples: {0}'.format(n_test))\n",
    "print('Number of test pixels: {0}'.format(n_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 7, 5, 4, 3, 6, 3, 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAACPCAYAAAAMe8GhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAOAAmy0AAAAAcIDNFgAAAAA48H8sYoCOWBcTrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f7841e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sel = np.random.randint(n_train, size=8)\n",
    "\n",
    "grid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
    "plt.rcParams['figure.figsize'] = (16, 2)\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    "print(*list(train_df.iloc[random_sel, 0].values), sep = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFFCAYAAABxMu67AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f0fcccba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())\n",
    "plt.xticks(np.arange(n_class))\n",
    "plt.xlabel('Class', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.grid('on', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotation Transformation\n",
    "Randomly rotate the image. Available in upcoming torchvision but not now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/tree/master/torchvision/transforms\n",
    "    Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Vertical and Horizontal Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data into Tensors\n",
    "For the training set, apply random rotation within the range of (-45, 45) degrees, shift by (-3, 3) pixels\n",
    "and normalize pixel values to [-1, 1].  For the test set, only apply nomalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = MNIST_data('../input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(), RandomRotation(degrees=45), RandomShift(3),\n",
    "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = MNIST_data('../input/test.csv')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jychang/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAADGCAYAAADFTho4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKGgAAEDy/hvCffNsBXusmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3f0f86d198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotate = RandomRotation(45)\n",
    "shift = RandomShift(3)\n",
    "composed = transforms.Compose([RandomRotation(45),\n",
    "                               RandomShift(3)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = transforms.ToPILImage()(train_df.iloc[65,1:].reshape((28,28)).astype(np.uint8)[:,:,None])\n",
    "for i, tsfrm in enumerate([rotate, shift, composed]):\n",
    "    transformed_sample = tsfrm(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128 * 3 * 3, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/42000 (0%)]\tLoss: 5.358752\n",
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 1.396061\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.924599\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.878184\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.378729\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.490264\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.357702\n",
      "\n",
      "Average loss: 0.1928, Accuracy: 39668/42000 (94%)\n",
      "\n",
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 0.277282\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.181907\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.164069\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.389159\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.339012\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.298699\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.249344\n",
      "\n",
      "Average loss: 0.1771, Accuracy: 39901/42000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/42000 (0%)]\tLoss: 0.580661\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.088132\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.311965\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.204177\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.108538\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.160813\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.088842\n",
      "\n",
      "Average loss: 0.1111, Accuracy: 40689/42000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/42000 (0%)]\tLoss: 0.211977\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.063094\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.212682\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.151332\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.163926\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.082918\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.351179\n",
      "\n",
      "Average loss: 0.0940, Accuracy: 40909/42000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/42000 (0%)]\tLoss: 0.222765\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.189817\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.109041\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.061258\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.050040\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.144510\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.078700\n",
      "\n",
      "Average loss: 0.1514, Accuracy: 40339/42000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/42000 (0%)]\tLoss: 0.068177\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.189601\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.273391\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.094253\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.065751\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.049201\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.092330\n",
      "\n",
      "Average loss: 0.0965, Accuracy: 40906/42000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/42000 (0%)]\tLoss: 0.063875\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.041371\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.014584\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.259125\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.186123\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.014706\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.141748\n",
      "\n",
      "Average loss: 0.0643, Accuracy: 41236/42000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/42000 (0%)]\tLoss: 0.341864\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.007626\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.055305\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.303727\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.024172\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.336344\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.011423\n",
      "\n",
      "Average loss: 0.0927, Accuracy: 40960/42000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/42000 (0%)]\tLoss: 0.019606\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.090033\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.039147\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.067257\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.042900\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.117159\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.023435\n",
      "\n",
      "Average loss: 0.0816, Accuracy: 41134/42000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/42000 (0%)]\tLoss: 0.082095\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.052452\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.081203\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.024322\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.013048\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.109299\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.019576\n",
      "\n",
      "Average loss: 0.0807, Accuracy: 41130/42000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/42000 (0%)]\tLoss: 0.155686\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.092286\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.120746\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.063891\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.083042\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.085596\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.246523\n",
      "\n",
      "Average loss: 0.0568, Accuracy: 41369/42000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/42000 (0%)]\tLoss: 0.122424\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.122959\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.257719\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.059021\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.031685\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.149715\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.214547\n",
      "\n",
      "Average loss: 0.0545, Accuracy: 41368/42000 (98%)\n",
      "\n",
      "Train Epoch: 12 [0/42000 (0%)]\tLoss: 0.028025\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.037820\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.055557\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.076837\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.042805\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.011398\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.104661\n",
      "\n",
      "Average loss: 0.0466, Accuracy: 41459/42000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/42000 (0%)]\tLoss: 0.082280\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.053561\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.026913\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.003346\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.053124\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.091621\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.034798\n",
      "\n",
      "Average loss: 0.0533, Accuracy: 41411/42000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/42000 (0%)]\tLoss: 0.033911\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.045820\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.019455\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.031518\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.005617\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.220099\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.005939\n",
      "\n",
      "Average loss: 0.0362, Accuracy: 41562/42000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/42000 (0%)]\tLoss: 0.044945\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.065110\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.013107\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.094799\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.109072\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.051973\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.068239\n",
      "\n",
      "Average loss: 0.0440, Accuracy: 41538/42000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/42000 (0%)]\tLoss: 0.016849\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.068881\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.020143\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.058850\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.046868\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.051048\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.094021\n",
      "\n",
      "Average loss: 0.0356, Accuracy: 41561/42000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/42000 (0%)]\tLoss: 0.006546\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.005699\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.030250\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.002961\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.016632\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.004070\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.017798\n",
      "\n",
      "Average loss: 0.0512, Accuracy: 41397/42000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/42000 (0%)]\tLoss: 0.005168\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.007013\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.004523\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.129949\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.156993\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.156694\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.041024\n",
      "\n",
      "Average loss: 0.0397, Accuracy: 41521/42000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/42000 (0%)]\tLoss: 0.015155\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.008804\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.048912\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.169819\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.056257\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.073759\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.011546\n",
      "\n",
      "Average loss: 0.0416, Accuracy: 41550/42000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/42000 (0%)]\tLoss: 0.281873\n",
      "Train Epoch: 20 [6400/42000 (15%)]\tLoss: 0.031273\n",
      "Train Epoch: 20 [12800/42000 (30%)]\tLoss: 0.094754\n",
      "Train Epoch: 20 [19200/42000 (46%)]\tLoss: 0.013825\n",
      "Train Epoch: 20 [25600/42000 (61%)]\tLoss: 0.013619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [32000/42000 (76%)]\tLoss: 0.006847\n",
      "Train Epoch: 20 [38400/42000 (91%)]\tLoss: 0.019286\n",
      "\n",
      "Average loss: 0.0402, Accuracy: 41576/42000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/42000 (0%)]\tLoss: 0.156475\n",
      "Train Epoch: 21 [6400/42000 (15%)]\tLoss: 0.105724\n",
      "Train Epoch: 21 [12800/42000 (30%)]\tLoss: 0.066454\n",
      "Train Epoch: 21 [19200/42000 (46%)]\tLoss: 0.073228\n",
      "Train Epoch: 21 [25600/42000 (61%)]\tLoss: 0.054301\n",
      "Train Epoch: 21 [32000/42000 (76%)]\tLoss: 0.006316\n",
      "Train Epoch: 21 [38400/42000 (91%)]\tLoss: 0.086152\n",
      "\n",
      "Average loss: 0.0363, Accuracy: 41585/42000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/42000 (0%)]\tLoss: 0.086656\n",
      "Train Epoch: 22 [6400/42000 (15%)]\tLoss: 0.053634\n",
      "Train Epoch: 22 [12800/42000 (30%)]\tLoss: 0.140414\n",
      "Train Epoch: 22 [19200/42000 (46%)]\tLoss: 0.013158\n",
      "Train Epoch: 22 [25600/42000 (61%)]\tLoss: 0.050386\n",
      "Train Epoch: 22 [32000/42000 (76%)]\tLoss: 0.165757\n",
      "Train Epoch: 22 [38400/42000 (91%)]\tLoss: 0.113012\n",
      "\n",
      "Average loss: 0.0426, Accuracy: 41528/42000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/42000 (0%)]\tLoss: 0.059387\n",
      "Train Epoch: 23 [6400/42000 (15%)]\tLoss: 0.063612\n",
      "Train Epoch: 23 [12800/42000 (30%)]\tLoss: 0.016294\n",
      "Train Epoch: 23 [19200/42000 (46%)]\tLoss: 0.002770\n",
      "Train Epoch: 23 [25600/42000 (61%)]\tLoss: 0.015480\n",
      "Train Epoch: 23 [32000/42000 (76%)]\tLoss: 0.018858\n",
      "Train Epoch: 23 [38400/42000 (91%)]\tLoss: 0.018079\n",
      "\n",
      "Average loss: 0.0357, Accuracy: 41580/42000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/42000 (0%)]\tLoss: 0.114721\n",
      "Train Epoch: 24 [6400/42000 (15%)]\tLoss: 0.042154\n",
      "Train Epoch: 24 [12800/42000 (30%)]\tLoss: 0.057150\n",
      "Train Epoch: 24 [19200/42000 (46%)]\tLoss: 0.079716\n",
      "Train Epoch: 24 [25600/42000 (61%)]\tLoss: 0.008393\n",
      "Train Epoch: 24 [32000/42000 (76%)]\tLoss: 0.014383\n",
      "Train Epoch: 24 [38400/42000 (91%)]\tLoss: 0.083225\n",
      "\n",
      "Average loss: 0.0378, Accuracy: 41573/42000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/42000 (0%)]\tLoss: 0.079570\n",
      "Train Epoch: 25 [6400/42000 (15%)]\tLoss: 0.022172\n",
      "Train Epoch: 25 [12800/42000 (30%)]\tLoss: 0.033918\n",
      "Train Epoch: 25 [19200/42000 (46%)]\tLoss: 0.032816\n",
      "Train Epoch: 25 [25600/42000 (61%)]\tLoss: 0.014400\n",
      "Train Epoch: 25 [32000/42000 (76%)]\tLoss: 0.027274\n",
      "Train Epoch: 25 [38400/42000 (91%)]\tLoss: 0.062814\n",
      "\n",
      "Average loss: 0.0284, Accuracy: 41663/42000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/42000 (0%)]\tLoss: 0.015265\n",
      "Train Epoch: 26 [6400/42000 (15%)]\tLoss: 0.025295\n",
      "Train Epoch: 26 [12800/42000 (30%)]\tLoss: 0.000979\n",
      "Train Epoch: 26 [19200/42000 (46%)]\tLoss: 0.073484\n",
      "Train Epoch: 26 [25600/42000 (61%)]\tLoss: 0.071060\n",
      "Train Epoch: 26 [32000/42000 (76%)]\tLoss: 0.091026\n",
      "Train Epoch: 26 [38400/42000 (91%)]\tLoss: 0.060848\n",
      "\n",
      "Average loss: 0.0357, Accuracy: 41597/42000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/42000 (0%)]\tLoss: 0.009484\n",
      "Train Epoch: 27 [6400/42000 (15%)]\tLoss: 0.047047\n",
      "Train Epoch: 27 [12800/42000 (30%)]\tLoss: 0.028550\n",
      "Train Epoch: 27 [19200/42000 (46%)]\tLoss: 0.011603\n",
      "Train Epoch: 27 [25600/42000 (61%)]\tLoss: 0.006102\n",
      "Train Epoch: 27 [32000/42000 (76%)]\tLoss: 0.001729\n",
      "Train Epoch: 27 [38400/42000 (91%)]\tLoss: 0.028742\n",
      "\n",
      "Average loss: 0.0452, Accuracy: 41398/42000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/42000 (0%)]\tLoss: 0.009187\n",
      "Train Epoch: 28 [6400/42000 (15%)]\tLoss: 0.084305\n",
      "Train Epoch: 28 [12800/42000 (30%)]\tLoss: 0.000570\n",
      "Train Epoch: 28 [19200/42000 (46%)]\tLoss: 0.015916\n",
      "Train Epoch: 28 [25600/42000 (61%)]\tLoss: 0.028195\n",
      "Train Epoch: 28 [32000/42000 (76%)]\tLoss: 0.019249\n",
      "Train Epoch: 28 [38400/42000 (91%)]\tLoss: 0.021618\n",
      "\n",
      "Average loss: 0.0351, Accuracy: 41601/42000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/42000 (0%)]\tLoss: 0.009536\n",
      "Train Epoch: 29 [6400/42000 (15%)]\tLoss: 0.001411\n",
      "Train Epoch: 29 [12800/42000 (30%)]\tLoss: 0.009106\n",
      "Train Epoch: 29 [19200/42000 (46%)]\tLoss: 0.056887\n",
      "Train Epoch: 29 [25600/42000 (61%)]\tLoss: 0.019731\n",
      "Train Epoch: 29 [32000/42000 (76%)]\tLoss: 0.049699\n",
      "Train Epoch: 29 [38400/42000 (91%)]\tLoss: 0.087010\n",
      "\n",
      "Average loss: 0.0294, Accuracy: 41667/42000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = prediciton(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/vgg_sub2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
