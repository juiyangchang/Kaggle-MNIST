{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network With PyTorch\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 42000\n",
      "Number of training pixels: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "\n",
    "n_train = len(train_df)\n",
    "n_pixels = len(train_df.columns) - 1\n",
    "n_class = len(set(train_df['label']))\n",
    "\n",
    "print('Number of training samples: {0}'.format(n_train))\n",
    "print('Number of training pixels: {0}'.format(n_pixels))\n",
    "print('Number of classes: {0}'.format(n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28000\n",
      "Number of test pixels: 784\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "n_test = len(test_df)\n",
    "n_pixels = len(test_df.columns)\n",
    "\n",
    "print('Number of train samples: {0}'.format(n_test))\n",
    "print('Number of test pixels: {0}'.format(n_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9, 7, 1, 2, 7, 0, 6, 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAACPCAYAAAAMe8GhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f475720bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sel = np.random.randint(n_train, size=8)\n",
    "\n",
    "grid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
    "plt.rcParams['figure.figsize'] = (16, 2)\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    "print(*list(train_df.iloc[random_sel, 0].values), sep = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFFCAYAAABxMu67AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f47c5cef518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())\n",
    "plt.xticks(np.arange(n_class))\n",
    "plt.xlabel('Class', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.grid('on', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotation Transformation\n",
    "Randomly rotate the image. Available in upcoming torchvision but not now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/tree/master/torchvision/transforms\n",
    "    Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Vertical and Horizontal Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data into Tensors\n",
    "For the training set, apply random rotation within the range of (-45, 45) degrees, shift by (-3, 3) pixels\n",
    "and normalize pixel values to [-1, 1].  For the test set, only apply nomalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = MNIST_data('../input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(), RandomRotation(degrees=45), RandomShift(3),\n",
    "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = MNIST_data('../input/test.csv')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jychang/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAADGCAYAAADFTho4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4758ddf3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotate = RandomRotation(45)\n",
    "shift = RandomShift(3)\n",
    "composed = transforms.Compose([RandomRotation(45),\n",
    "                               RandomShift(3)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = transforms.ToPILImage()(train_df.iloc[65,1:].reshape((28,28)).astype(np.uint8)[:,:,None])\n",
    "for i, tsfrm in enumerate([rotate, shift, composed]):\n",
    "    transformed_sample = tsfrm(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/42000 (0%)]\tLoss: 3.310847\n",
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.785414\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.340852\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.363056\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.296376\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.388557\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.191138\n",
      "\n",
      "Average loss: 0.1878, Accuracy: 39554/42000 (94%)\n",
      "\n",
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 0.393669\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.488942\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.253717\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.180582\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.226615\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.064390\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.188599\n",
      "\n",
      "Average loss: 0.1011, Accuracy: 40632/42000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/42000 (0%)]\tLoss: 0.105255\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.145305\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.216606\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.235137\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.126859\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.030693\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.070453\n",
      "\n",
      "Average loss: 0.0951, Accuracy: 40756/42000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/42000 (0%)]\tLoss: 0.113311\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.081714\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.113839\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.272403\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.215126\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.095727\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.064560\n",
      "\n",
      "Average loss: 0.1106, Accuracy: 40583/42000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/42000 (0%)]\tLoss: 0.104389\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.085592\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.204006\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.044812\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.118275\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.117959\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.226831\n",
      "\n",
      "Average loss: 0.0688, Accuracy: 41132/42000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/42000 (0%)]\tLoss: 0.149760\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.152361\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.194504\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.192681\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.045626\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.093506\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.131705\n",
      "\n",
      "Average loss: 0.0634, Accuracy: 41198/42000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/42000 (0%)]\tLoss: 0.036531\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.078061\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.274474\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.055675\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.120892\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.213244\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.048738\n",
      "\n",
      "Average loss: 0.0621, Accuracy: 41195/42000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/42000 (0%)]\tLoss: 0.160597\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.166944\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.200908\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.008094\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.061188\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.112303\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.050393\n",
      "\n",
      "Average loss: 0.0571, Accuracy: 41256/42000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/42000 (0%)]\tLoss: 0.236330\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.115080\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.088980\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.134173\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.086490\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.103624\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.041362\n",
      "\n",
      "Average loss: 0.0529, Accuracy: 41314/42000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/42000 (0%)]\tLoss: 0.077896\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.024969\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.074466\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.033230\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.099104\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.048707\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.046717\n",
      "\n",
      "Average loss: 0.0517, Accuracy: 41337/42000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/42000 (0%)]\tLoss: 0.225838\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.093739\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.119974\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.129817\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.075996\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.037178\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.052655\n",
      "\n",
      "Average loss: 0.0502, Accuracy: 41354/42000 (98%)\n",
      "\n",
      "Train Epoch: 11 [0/42000 (0%)]\tLoss: 0.063109\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.027570\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.144177\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.260809\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.595234\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.031464\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.014465\n",
      "\n",
      "Average loss: 0.0463, Accuracy: 41396/42000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/42000 (0%)]\tLoss: 0.110852\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.025464\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.094710\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.037697\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.065042\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.076041\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.155816\n",
      "\n",
      "Average loss: 0.0423, Accuracy: 41459/42000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/42000 (0%)]\tLoss: 0.153290\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.267098\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.043880\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.084617\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.048681\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.076367\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.033161\n",
      "\n",
      "Average loss: 0.0436, Accuracy: 41402/42000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/42000 (0%)]\tLoss: 0.040745\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.190789\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.195399\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.024393\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.231488\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.116267\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.193841\n",
      "\n",
      "Average loss: 0.0419, Accuracy: 41452/42000 (99%)\n",
      "\n",
      "Train Epoch: 15 [0/42000 (0%)]\tLoss: 0.169317\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.077294\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.063218\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.037155\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.135441\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.145471\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.211569\n",
      "\n",
      "Average loss: 0.0425, Accuracy: 41455/42000 (99%)\n",
      "\n",
      "Train Epoch: 16 [0/42000 (0%)]\tLoss: 0.024554\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.175475\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.074945\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.158123\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.038481\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.071368\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.139683\n",
      "\n",
      "Average loss: 0.0385, Accuracy: 41485/42000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/42000 (0%)]\tLoss: 0.047919\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.026273\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.137079\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.029365\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.024826\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.090648\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.027124\n",
      "\n",
      "Average loss: 0.0418, Accuracy: 41463/42000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/42000 (0%)]\tLoss: 0.055330\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.061924\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.024640\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.103500\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.056869\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.080980\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.082677\n",
      "\n",
      "Average loss: 0.0402, Accuracy: 41475/42000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/42000 (0%)]\tLoss: 0.122168\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.035911\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.115799\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.063962\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.009892\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.082504\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.094253\n",
      "\n",
      "Average loss: 0.0377, Accuracy: 41494/42000 (99%)\n",
      "\n",
      "Train Epoch: 20 [0/42000 (0%)]\tLoss: 0.060961\n",
      "Train Epoch: 20 [6400/42000 (15%)]\tLoss: 0.025347\n",
      "Train Epoch: 20 [12800/42000 (30%)]\tLoss: 0.147787\n",
      "Train Epoch: 20 [19200/42000 (46%)]\tLoss: 0.055378\n",
      "Train Epoch: 20 [25600/42000 (61%)]\tLoss: 0.055082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [32000/42000 (76%)]\tLoss: 0.092450\n",
      "Train Epoch: 20 [38400/42000 (91%)]\tLoss: 0.093611\n",
      "\n",
      "Average loss: 0.0352, Accuracy: 41511/42000 (99%)\n",
      "\n",
      "Train Epoch: 21 [0/42000 (0%)]\tLoss: 0.125724\n",
      "Train Epoch: 21 [6400/42000 (15%)]\tLoss: 0.008134\n",
      "Train Epoch: 21 [12800/42000 (30%)]\tLoss: 0.127898\n",
      "Train Epoch: 21 [19200/42000 (46%)]\tLoss: 0.251736\n",
      "Train Epoch: 21 [25600/42000 (61%)]\tLoss: 0.083047\n",
      "Train Epoch: 21 [32000/42000 (76%)]\tLoss: 0.011789\n",
      "Train Epoch: 21 [38400/42000 (91%)]\tLoss: 0.069844\n",
      "\n",
      "Average loss: 0.0413, Accuracy: 41448/42000 (99%)\n",
      "\n",
      "Train Epoch: 22 [0/42000 (0%)]\tLoss: 0.033533\n",
      "Train Epoch: 22 [6400/42000 (15%)]\tLoss: 0.011230\n",
      "Train Epoch: 22 [12800/42000 (30%)]\tLoss: 0.038036\n",
      "Train Epoch: 22 [19200/42000 (46%)]\tLoss: 0.036746\n",
      "Train Epoch: 22 [25600/42000 (61%)]\tLoss: 0.049262\n",
      "Train Epoch: 22 [32000/42000 (76%)]\tLoss: 0.101168\n",
      "Train Epoch: 22 [38400/42000 (91%)]\tLoss: 0.037836\n",
      "\n",
      "Average loss: 0.0342, Accuracy: 41562/42000 (99%)\n",
      "\n",
      "Train Epoch: 23 [0/42000 (0%)]\tLoss: 0.039079\n",
      "Train Epoch: 23 [6400/42000 (15%)]\tLoss: 0.111554\n",
      "Train Epoch: 23 [12800/42000 (30%)]\tLoss: 0.096242\n",
      "Train Epoch: 23 [19200/42000 (46%)]\tLoss: 0.032108\n",
      "Train Epoch: 23 [25600/42000 (61%)]\tLoss: 0.010032\n",
      "Train Epoch: 23 [32000/42000 (76%)]\tLoss: 0.195557\n",
      "Train Epoch: 23 [38400/42000 (91%)]\tLoss: 0.061509\n",
      "\n",
      "Average loss: 0.0374, Accuracy: 41519/42000 (99%)\n",
      "\n",
      "Train Epoch: 24 [0/42000 (0%)]\tLoss: 0.038797\n",
      "Train Epoch: 24 [6400/42000 (15%)]\tLoss: 0.142418\n",
      "Train Epoch: 24 [12800/42000 (30%)]\tLoss: 0.037706\n",
      "Train Epoch: 24 [19200/42000 (46%)]\tLoss: 0.063152\n",
      "Train Epoch: 24 [25600/42000 (61%)]\tLoss: 0.280125\n",
      "Train Epoch: 24 [32000/42000 (76%)]\tLoss: 0.011559\n",
      "Train Epoch: 24 [38400/42000 (91%)]\tLoss: 0.016123\n",
      "\n",
      "Average loss: 0.0332, Accuracy: 41576/42000 (99%)\n",
      "\n",
      "Train Epoch: 25 [0/42000 (0%)]\tLoss: 0.033737\n",
      "Train Epoch: 25 [6400/42000 (15%)]\tLoss: 0.242414\n",
      "Train Epoch: 25 [12800/42000 (30%)]\tLoss: 0.051373\n",
      "Train Epoch: 25 [19200/42000 (46%)]\tLoss: 0.105942\n",
      "Train Epoch: 25 [25600/42000 (61%)]\tLoss: 0.125080\n",
      "Train Epoch: 25 [32000/42000 (76%)]\tLoss: 0.120248\n",
      "Train Epoch: 25 [38400/42000 (91%)]\tLoss: 0.052290\n",
      "\n",
      "Average loss: 0.0331, Accuracy: 41567/42000 (99%)\n",
      "\n",
      "Train Epoch: 26 [0/42000 (0%)]\tLoss: 0.057044\n",
      "Train Epoch: 26 [6400/42000 (15%)]\tLoss: 0.011774\n",
      "Train Epoch: 26 [12800/42000 (30%)]\tLoss: 0.080036\n",
      "Train Epoch: 26 [19200/42000 (46%)]\tLoss: 0.018444\n",
      "Train Epoch: 26 [25600/42000 (61%)]\tLoss: 0.029088\n",
      "Train Epoch: 26 [32000/42000 (76%)]\tLoss: 0.069347\n",
      "Train Epoch: 26 [38400/42000 (91%)]\tLoss: 0.034325\n",
      "\n",
      "Average loss: 0.0358, Accuracy: 41540/42000 (99%)\n",
      "\n",
      "Train Epoch: 27 [0/42000 (0%)]\tLoss: 0.114034\n",
      "Train Epoch: 27 [6400/42000 (15%)]\tLoss: 0.051171\n",
      "Train Epoch: 27 [12800/42000 (30%)]\tLoss: 0.065904\n",
      "Train Epoch: 27 [19200/42000 (46%)]\tLoss: 0.245639\n",
      "Train Epoch: 27 [25600/42000 (61%)]\tLoss: 0.171845\n",
      "Train Epoch: 27 [32000/42000 (76%)]\tLoss: 0.004153\n",
      "Train Epoch: 27 [38400/42000 (91%)]\tLoss: 0.049359\n",
      "\n",
      "Average loss: 0.0336, Accuracy: 41583/42000 (99%)\n",
      "\n",
      "Train Epoch: 28 [0/42000 (0%)]\tLoss: 0.057286\n",
      "Train Epoch: 28 [6400/42000 (15%)]\tLoss: 0.134603\n",
      "Train Epoch: 28 [12800/42000 (30%)]\tLoss: 0.044224\n",
      "Train Epoch: 28 [19200/42000 (46%)]\tLoss: 0.065877\n",
      "Train Epoch: 28 [25600/42000 (61%)]\tLoss: 0.081629\n",
      "Train Epoch: 28 [32000/42000 (76%)]\tLoss: 0.001439\n",
      "Train Epoch: 28 [38400/42000 (91%)]\tLoss: 0.135911\n",
      "\n",
      "Average loss: 0.0332, Accuracy: 41561/42000 (99%)\n",
      "\n",
      "Train Epoch: 29 [0/42000 (0%)]\tLoss: 0.073815\n",
      "Train Epoch: 29 [6400/42000 (15%)]\tLoss: 0.024312\n",
      "Train Epoch: 29 [12800/42000 (30%)]\tLoss: 0.029938\n",
      "Train Epoch: 29 [19200/42000 (46%)]\tLoss: 0.023942\n",
      "Train Epoch: 29 [25600/42000 (61%)]\tLoss: 0.134512\n",
      "Train Epoch: 29 [32000/42000 (76%)]\tLoss: 0.019065\n",
      "Train Epoch: 29 [38400/42000 (91%)]\tLoss: 0.071777\n",
      "\n",
      "Average loss: 0.0333, Accuracy: 41566/42000 (99%)\n",
      "\n",
      "Train Epoch: 30 [0/42000 (0%)]\tLoss: 0.155341\n",
      "Train Epoch: 30 [6400/42000 (15%)]\tLoss: 0.087879\n",
      "Train Epoch: 30 [12800/42000 (30%)]\tLoss: 0.009879\n",
      "Train Epoch: 30 [19200/42000 (46%)]\tLoss: 0.038626\n",
      "Train Epoch: 30 [25600/42000 (61%)]\tLoss: 0.041288\n",
      "Train Epoch: 30 [32000/42000 (76%)]\tLoss: 0.086250\n",
      "Train Epoch: 30 [38400/42000 (91%)]\tLoss: 0.070778\n",
      "\n",
      "Average loss: 0.0327, Accuracy: 41577/42000 (99%)\n",
      "\n",
      "Train Epoch: 31 [0/42000 (0%)]\tLoss: 0.004641\n",
      "Train Epoch: 31 [6400/42000 (15%)]\tLoss: 0.093369\n",
      "Train Epoch: 31 [12800/42000 (30%)]\tLoss: 0.075084\n",
      "Train Epoch: 31 [19200/42000 (46%)]\tLoss: 0.011373\n",
      "Train Epoch: 31 [25600/42000 (61%)]\tLoss: 0.039859\n",
      "Train Epoch: 31 [32000/42000 (76%)]\tLoss: 0.157102\n",
      "Train Epoch: 31 [38400/42000 (91%)]\tLoss: 0.065405\n",
      "\n",
      "Average loss: 0.0311, Accuracy: 41590/42000 (99%)\n",
      "\n",
      "Train Epoch: 32 [0/42000 (0%)]\tLoss: 0.259238\n",
      "Train Epoch: 32 [6400/42000 (15%)]\tLoss: 0.038797\n",
      "Train Epoch: 32 [12800/42000 (30%)]\tLoss: 0.018010\n",
      "Train Epoch: 32 [19200/42000 (46%)]\tLoss: 0.014486\n",
      "Train Epoch: 32 [25600/42000 (61%)]\tLoss: 0.044649\n",
      "Train Epoch: 32 [32000/42000 (76%)]\tLoss: 0.007873\n",
      "Train Epoch: 32 [38400/42000 (91%)]\tLoss: 0.114795\n",
      "\n",
      "Average loss: 0.0277, Accuracy: 41628/42000 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/42000 (0%)]\tLoss: 0.021373\n",
      "Train Epoch: 33 [6400/42000 (15%)]\tLoss: 0.017033\n",
      "Train Epoch: 33 [12800/42000 (30%)]\tLoss: 0.064848\n",
      "Train Epoch: 33 [19200/42000 (46%)]\tLoss: 0.011943\n",
      "Train Epoch: 33 [25600/42000 (61%)]\tLoss: 0.008097\n",
      "Train Epoch: 33 [32000/42000 (76%)]\tLoss: 0.013104\n",
      "Train Epoch: 33 [38400/42000 (91%)]\tLoss: 0.032655\n",
      "\n",
      "Average loss: 0.0298, Accuracy: 41611/42000 (99%)\n",
      "\n",
      "Train Epoch: 34 [0/42000 (0%)]\tLoss: 0.019089\n",
      "Train Epoch: 34 [6400/42000 (15%)]\tLoss: 0.094145\n",
      "Train Epoch: 34 [12800/42000 (30%)]\tLoss: 0.084175\n",
      "Train Epoch: 34 [19200/42000 (46%)]\tLoss: 0.009028\n",
      "Train Epoch: 34 [25600/42000 (61%)]\tLoss: 0.143090\n",
      "Train Epoch: 34 [32000/42000 (76%)]\tLoss: 0.026819\n",
      "Train Epoch: 34 [38400/42000 (91%)]\tLoss: 0.084059\n",
      "\n",
      "Average loss: 0.0297, Accuracy: 41612/42000 (99%)\n",
      "\n",
      "Train Epoch: 35 [0/42000 (0%)]\tLoss: 0.011670\n",
      "Train Epoch: 35 [6400/42000 (15%)]\tLoss: 0.028698\n",
      "Train Epoch: 35 [12800/42000 (30%)]\tLoss: 0.109310\n",
      "Train Epoch: 35 [19200/42000 (46%)]\tLoss: 0.062422\n",
      "Train Epoch: 35 [25600/42000 (61%)]\tLoss: 0.027126\n",
      "Train Epoch: 35 [32000/42000 (76%)]\tLoss: 0.051891\n",
      "Train Epoch: 35 [38400/42000 (91%)]\tLoss: 0.060105\n",
      "\n",
      "Average loss: 0.0263, Accuracy: 41642/42000 (99%)\n",
      "\n",
      "Train Epoch: 36 [0/42000 (0%)]\tLoss: 0.005532\n",
      "Train Epoch: 36 [6400/42000 (15%)]\tLoss: 0.014055\n",
      "Train Epoch: 36 [12800/42000 (30%)]\tLoss: 0.011410\n",
      "Train Epoch: 36 [19200/42000 (46%)]\tLoss: 0.034419\n",
      "Train Epoch: 36 [25600/42000 (61%)]\tLoss: 0.063373\n",
      "Train Epoch: 36 [32000/42000 (76%)]\tLoss: 0.013650\n",
      "Train Epoch: 36 [38400/42000 (91%)]\tLoss: 0.037612\n",
      "\n",
      "Average loss: 0.0271, Accuracy: 41639/42000 (99%)\n",
      "\n",
      "Train Epoch: 37 [0/42000 (0%)]\tLoss: 0.156881\n",
      "Train Epoch: 37 [6400/42000 (15%)]\tLoss: 0.031831\n",
      "Train Epoch: 37 [12800/42000 (30%)]\tLoss: 0.120715\n",
      "Train Epoch: 37 [19200/42000 (46%)]\tLoss: 0.021604\n",
      "Train Epoch: 37 [25600/42000 (61%)]\tLoss: 0.034418\n",
      "Train Epoch: 37 [32000/42000 (76%)]\tLoss: 0.162945\n",
      "Train Epoch: 37 [38400/42000 (91%)]\tLoss: 0.076093\n",
      "\n",
      "Average loss: 0.0282, Accuracy: 41638/42000 (99%)\n",
      "\n",
      "Train Epoch: 38 [0/42000 (0%)]\tLoss: 0.048165\n",
      "Train Epoch: 38 [6400/42000 (15%)]\tLoss: 0.128940\n",
      "Train Epoch: 38 [12800/42000 (30%)]\tLoss: 0.016488\n",
      "Train Epoch: 38 [19200/42000 (46%)]\tLoss: 0.018588\n",
      "Train Epoch: 38 [25600/42000 (61%)]\tLoss: 0.039349\n",
      "Train Epoch: 38 [32000/42000 (76%)]\tLoss: 0.087721\n",
      "Train Epoch: 38 [38400/42000 (91%)]\tLoss: 0.036932\n",
      "\n",
      "Average loss: 0.0274, Accuracy: 41651/42000 (99%)\n",
      "\n",
      "Train Epoch: 39 [0/42000 (0%)]\tLoss: 0.185651\n",
      "Train Epoch: 39 [6400/42000 (15%)]\tLoss: 0.072945\n",
      "Train Epoch: 39 [12800/42000 (30%)]\tLoss: 0.041602\n",
      "Train Epoch: 39 [19200/42000 (46%)]\tLoss: 0.080655\n",
      "Train Epoch: 39 [25600/42000 (61%)]\tLoss: 0.036516\n",
      "Train Epoch: 39 [32000/42000 (76%)]\tLoss: 0.049338\n",
      "Train Epoch: 39 [38400/42000 (91%)]\tLoss: 0.012854\n",
      "\n",
      "Average loss: 0.0271, Accuracy: 41647/42000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = prediciton(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/vgg_sub3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
