{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network With PyTorch\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 42000\n",
      "Number of training pixels: 784\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "\n",
    "n_train = len(train_df)\n",
    "n_pixels = len(train_df.columns) - 1\n",
    "n_class = len(set(train_df['label']))\n",
    "\n",
    "print('Number of training samples: {0}'.format(n_train))\n",
    "print('Number of training pixels: {0}'.format(n_pixels))\n",
    "print('Number of classes: {0}'.format(n_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 28000\n",
      "Number of test pixels: 784\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "n_test = len(test_df)\n",
    "n_pixels = len(test_df.columns)\n",
    "\n",
    "print('Number of train samples: {0}'.format(n_test))\n",
    "print('Number of test pixels: {0}'.format(n_pixels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 9, 7, 0, 2, 5, 2, 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAACPCAYAAAAMe8GhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB3vSy6Qo4RgNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f038af3ef98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sel = np.random.randint(n_train, size=8)\n",
    "\n",
    "grid = make_grid(torch.Tensor((train_df.iloc[random_sel, 1:].as_matrix()/255.).reshape((-1, 28, 28))).unsqueeze(1), nrow=8)\n",
    "plt.rcParams['figure.figsize'] = (16, 2)\n",
    "plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "plt.axis('off')\n",
    "print(*list(train_df.iloc[random_sel, 0].values), sep = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFFCAYAAABxMu67AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f03309cdbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "plt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())\n",
    "plt.xticks(np.arange(n_class))\n",
    "plt.xlabel('Class', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=16)\n",
    "plt.grid('on', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    \"\"\"MNIST dtaa set\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Rotation Transformation\n",
    "Randomly rotate the image. Available in upcoming torchvision but not now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    \"\"\"\n",
    "    https://github.com/pytorch/vision/tree/master/torchvision/transforms\n",
    "    Rotate the image by angle.\n",
    "    Args:\n",
    "        degrees (sequence or float or int): Range of degrees to select from.\n",
    "            If degrees is a number instead of sequence like (min, max), the range of degrees\n",
    "            will be (-degrees, +degrees).\n",
    "        resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "        expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "        center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Vertical and Horizontal Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data into Tensors\n",
    "For the training set, apply random rotation within the range of (-45, 45) degrees, shift by (-3, 3) pixels\n",
    "and normalize pixel values to [-1, 1].  For the test set, only apply nomalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = MNIST_data('../input/train.csv', transform= transforms.Compose(\n",
    "                            [transforms.ToPILImage(), RandomRotation(degrees=20), RandomShift(3),\n",
    "                             transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = MNIST_data('../input/test.csv')\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jychang/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:8: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAADGCAYAAADFTho4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f032e36e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rotate = RandomRotation(20)\n",
    "shift = RandomShift(3)\n",
    "composed = transforms.Compose([RandomRotation(20),\n",
    "                               RandomShift(3)])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = transforms.ToPILImage()(train_df.iloc[65,1:].reshape((28,28)).astype(np.uint8)[:,:,None])\n",
    "for i, tsfrm in enumerate([rotate, shift, composed]):\n",
    "    transformed_sample = tsfrm(sample)\n",
    "\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    ax.imshow(np.reshape(np.array(list(transformed_sample.getdata())), (-1,28)), cmap='gray')    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.504863\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.323987\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.369905\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.281339\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.250864\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.273977\n",
      "\n",
      "Average loss: 0.1044, Accuracy: 40661/42000 (96.812%)\n",
      "\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.180819\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.140851\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.079687\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.117455\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.104464\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.044327\n",
      "\n",
      "Average loss: 0.0673, Accuracy: 41117/42000 (97.898%)\n",
      "\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.097550\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.045921\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.105045\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.091692\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.057986\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.132115\n",
      "\n",
      "Average loss: 0.0593, Accuracy: 41231/42000 (98.169%)\n",
      "\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.180276\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.106182\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.041297\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.101818\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.208341\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.092765\n",
      "\n",
      "Average loss: 0.0599, Accuracy: 41230/42000 (98.167%)\n",
      "\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.329866\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.071675\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.096387\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.131284\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.139025\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.182238\n",
      "\n",
      "Average loss: 0.0510, Accuracy: 41317/42000 (98.374%)\n",
      "\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.018605\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.035502\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.201129\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.088012\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.125437\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.084863\n",
      "\n",
      "Average loss: 0.0389, Accuracy: 41488/42000 (98.781%)\n",
      "\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.113996\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.078444\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.057222\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.036828\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.169637\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.005021\n",
      "\n",
      "Average loss: 0.0438, Accuracy: 41444/42000 (98.676%)\n",
      "\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.072805\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.154754\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.039793\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.073648\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.105036\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.004939\n",
      "\n",
      "Average loss: 0.0295, Accuracy: 41636/42000 (99.133%)\n",
      "\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.005104\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.017510\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.049817\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.059841\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.076049\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.058697\n",
      "\n",
      "Average loss: 0.0283, Accuracy: 41632/42000 (99.124%)\n",
      "\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.042466\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.070577\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.007356\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.018879\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.050329\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.008079\n",
      "\n",
      "Average loss: 0.0258, Accuracy: 41678/42000 (99.233%)\n",
      "\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.021977\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.036511\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.024425\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.049500\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.075788\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.026182\n",
      "\n",
      "Average loss: 0.0267, Accuracy: 41662/42000 (99.195%)\n",
      "\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.004125\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.032921\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.042537\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.166935\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.078714\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.007103\n",
      "\n",
      "Average loss: 0.0249, Accuracy: 41664/42000 (99.200%)\n",
      "\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.166746\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.016433\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.048742\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.036519\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.003023\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.007339\n",
      "\n",
      "Average loss: 0.0239, Accuracy: 41692/42000 (99.267%)\n",
      "\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.087536\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.046985\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.037016\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.044787\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.005012\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.005722\n",
      "\n",
      "Average loss: 0.0238, Accuracy: 41693/42000 (99.269%)\n",
      "\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.051399\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.021806\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.070613\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.010098\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.002111\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.115934\n",
      "\n",
      "Average loss: 0.0240, Accuracy: 41697/42000 (99.279%)\n",
      "\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.032380\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.075409\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.007131\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.020227\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.049631\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.020345\n",
      "\n",
      "Average loss: 0.0219, Accuracy: 41714/42000 (99.319%)\n",
      "\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.014933\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.049030\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.026892\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.146385\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.096144\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.054960\n",
      "\n",
      "Average loss: 0.0233, Accuracy: 41698/42000 (99.281%)\n",
      "\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.043838\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.024956\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.023575\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.048387\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.021129\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.004296\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41720/42000 (99.333%)\n",
      "\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.025355\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.084469\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.112074\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.046580\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.022044\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.013019\n",
      "\n",
      "Average loss: 0.0223, Accuracy: 41706/42000 (99.300%)\n",
      "\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.025214\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.049937\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.021258\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.017524\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.004604\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.047345\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41724/42000 (99.343%)\n",
      "\n",
      "Train Epoch: 20 [6400/42000 (15%)]\tLoss: 0.005991\n",
      "Train Epoch: 20 [12800/42000 (30%)]\tLoss: 0.140879\n",
      "Train Epoch: 20 [19200/42000 (46%)]\tLoss: 0.069101\n",
      "Train Epoch: 20 [25600/42000 (61%)]\tLoss: 0.051804\n",
      "Train Epoch: 20 [32000/42000 (76%)]\tLoss: 0.073006\n",
      "Train Epoch: 20 [38400/42000 (91%)]\tLoss: 0.086215\n",
      "\n",
      "Average loss: 0.0226, Accuracy: 41717/42000 (99.326%)\n",
      "\n",
      "Train Epoch: 21 [6400/42000 (15%)]\tLoss: 0.023347\n",
      "Train Epoch: 21 [12800/42000 (30%)]\tLoss: 0.019818\n",
      "Train Epoch: 21 [19200/42000 (46%)]\tLoss: 0.116752\n",
      "Train Epoch: 21 [25600/42000 (61%)]\tLoss: 0.003448\n",
      "Train Epoch: 21 [32000/42000 (76%)]\tLoss: 0.003101\n",
      "Train Epoch: 21 [38400/42000 (91%)]\tLoss: 0.020870\n",
      "\n",
      "Average loss: 0.0212, Accuracy: 41715/42000 (99.321%)\n",
      "\n",
      "Train Epoch: 22 [6400/42000 (15%)]\tLoss: 0.056499\n",
      "Train Epoch: 22 [12800/42000 (30%)]\tLoss: 0.089176\n",
      "Train Epoch: 22 [19200/42000 (46%)]\tLoss: 0.004533\n",
      "Train Epoch: 22 [25600/42000 (61%)]\tLoss: 0.011021\n",
      "Train Epoch: 22 [32000/42000 (76%)]\tLoss: 0.045164\n",
      "Train Epoch: 22 [38400/42000 (91%)]\tLoss: 0.011643\n",
      "\n",
      "Average loss: 0.0225, Accuracy: 41709/42000 (99.307%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 23 [6400/42000 (15%)]\tLoss: 0.086115\n",
      "Train Epoch: 23 [12800/42000 (30%)]\tLoss: 0.098285\n",
      "Train Epoch: 23 [19200/42000 (46%)]\tLoss: 0.005209\n",
      "Train Epoch: 23 [25600/42000 (61%)]\tLoss: 0.020911\n",
      "Train Epoch: 23 [32000/42000 (76%)]\tLoss: 0.061304\n",
      "Train Epoch: 23 [38400/42000 (91%)]\tLoss: 0.010841\n",
      "\n",
      "Average loss: 0.0212, Accuracy: 41736/42000 (99.371%)\n",
      "\n",
      "Train Epoch: 24 [6400/42000 (15%)]\tLoss: 0.018529\n",
      "Train Epoch: 24 [12800/42000 (30%)]\tLoss: 0.032479\n",
      "Train Epoch: 24 [19200/42000 (46%)]\tLoss: 0.078785\n",
      "Train Epoch: 24 [25600/42000 (61%)]\tLoss: 0.014089\n",
      "Train Epoch: 24 [32000/42000 (76%)]\tLoss: 0.018208\n",
      "Train Epoch: 24 [38400/42000 (91%)]\tLoss: 0.001817\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41708/42000 (99.305%)\n",
      "\n",
      "Train Epoch: 25 [6400/42000 (15%)]\tLoss: 0.015109\n",
      "Train Epoch: 25 [12800/42000 (30%)]\tLoss: 0.005014\n",
      "Train Epoch: 25 [19200/42000 (46%)]\tLoss: 0.006439\n",
      "Train Epoch: 25 [25600/42000 (61%)]\tLoss: 0.130867\n",
      "Train Epoch: 25 [32000/42000 (76%)]\tLoss: 0.103205\n",
      "Train Epoch: 25 [38400/42000 (91%)]\tLoss: 0.109345\n",
      "\n",
      "Average loss: 0.0222, Accuracy: 41699/42000 (99.283%)\n",
      "\n",
      "Train Epoch: 26 [6400/42000 (15%)]\tLoss: 0.035869\n",
      "Train Epoch: 26 [12800/42000 (30%)]\tLoss: 0.032934\n",
      "Train Epoch: 26 [19200/42000 (46%)]\tLoss: 0.040502\n",
      "Train Epoch: 26 [25600/42000 (61%)]\tLoss: 0.029748\n",
      "Train Epoch: 26 [32000/42000 (76%)]\tLoss: 0.033346\n",
      "Train Epoch: 26 [38400/42000 (91%)]\tLoss: 0.035797\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41719/42000 (99.331%)\n",
      "\n",
      "Train Epoch: 27 [6400/42000 (15%)]\tLoss: 0.067069\n",
      "Train Epoch: 27 [12800/42000 (30%)]\tLoss: 0.017701\n",
      "Train Epoch: 27 [19200/42000 (46%)]\tLoss: 0.081587\n",
      "Train Epoch: 27 [25600/42000 (61%)]\tLoss: 0.027806\n",
      "Train Epoch: 27 [32000/42000 (76%)]\tLoss: 0.008961\n",
      "Train Epoch: 27 [38400/42000 (91%)]\tLoss: 0.079904\n",
      "\n",
      "Average loss: 0.0221, Accuracy: 41706/42000 (99.300%)\n",
      "\n",
      "Train Epoch: 28 [6400/42000 (15%)]\tLoss: 0.005898\n",
      "Train Epoch: 28 [12800/42000 (30%)]\tLoss: 0.010553\n",
      "Train Epoch: 28 [19200/42000 (46%)]\tLoss: 0.025131\n",
      "Train Epoch: 28 [25600/42000 (61%)]\tLoss: 0.005661\n",
      "Train Epoch: 28 [32000/42000 (76%)]\tLoss: 0.048863\n",
      "Train Epoch: 28 [38400/42000 (91%)]\tLoss: 0.012902\n",
      "\n",
      "Average loss: 0.0212, Accuracy: 41715/42000 (99.321%)\n",
      "\n",
      "Train Epoch: 29 [6400/42000 (15%)]\tLoss: 0.029817\n",
      "Train Epoch: 29 [12800/42000 (30%)]\tLoss: 0.016493\n",
      "Train Epoch: 29 [19200/42000 (46%)]\tLoss: 0.037439\n",
      "Train Epoch: 29 [25600/42000 (61%)]\tLoss: 0.021838\n",
      "Train Epoch: 29 [32000/42000 (76%)]\tLoss: 0.144093\n",
      "Train Epoch: 29 [38400/42000 (91%)]\tLoss: 0.017291\n",
      "\n",
      "Average loss: 0.0216, Accuracy: 41695/42000 (99.274%)\n",
      "\n",
      "Train Epoch: 30 [6400/42000 (15%)]\tLoss: 0.008336\n",
      "Train Epoch: 30 [12800/42000 (30%)]\tLoss: 0.025076\n",
      "Train Epoch: 30 [19200/42000 (46%)]\tLoss: 0.118454\n",
      "Train Epoch: 30 [25600/42000 (61%)]\tLoss: 0.029106\n",
      "Train Epoch: 30 [32000/42000 (76%)]\tLoss: 0.012294\n",
      "Train Epoch: 30 [38400/42000 (91%)]\tLoss: 0.017180\n",
      "\n",
      "Average loss: 0.0232, Accuracy: 41699/42000 (99.283%)\n",
      "\n",
      "Train Epoch: 31 [6400/42000 (15%)]\tLoss: 0.023811\n",
      "Train Epoch: 31 [12800/42000 (30%)]\tLoss: 0.051879\n",
      "Train Epoch: 31 [19200/42000 (46%)]\tLoss: 0.036036\n",
      "Train Epoch: 31 [25600/42000 (61%)]\tLoss: 0.007900\n",
      "Train Epoch: 31 [32000/42000 (76%)]\tLoss: 0.014930\n",
      "Train Epoch: 31 [38400/42000 (91%)]\tLoss: 0.027859\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41721/42000 (99.336%)\n",
      "\n",
      "Train Epoch: 32 [6400/42000 (15%)]\tLoss: 0.009205\n",
      "Train Epoch: 32 [12800/42000 (30%)]\tLoss: 0.119959\n",
      "Train Epoch: 32 [19200/42000 (46%)]\tLoss: 0.008425\n",
      "Train Epoch: 32 [25600/42000 (61%)]\tLoss: 0.005089\n",
      "Train Epoch: 32 [32000/42000 (76%)]\tLoss: 0.007589\n",
      "Train Epoch: 32 [38400/42000 (91%)]\tLoss: 0.004932\n",
      "\n",
      "Average loss: 0.0211, Accuracy: 41722/42000 (99.338%)\n",
      "\n",
      "Train Epoch: 33 [6400/42000 (15%)]\tLoss: 0.017274\n",
      "Train Epoch: 33 [12800/42000 (30%)]\tLoss: 0.042004\n",
      "Train Epoch: 33 [19200/42000 (46%)]\tLoss: 0.001681\n",
      "Train Epoch: 33 [25600/42000 (61%)]\tLoss: 0.010777\n",
      "Train Epoch: 33 [32000/42000 (76%)]\tLoss: 0.016665\n",
      "Train Epoch: 33 [38400/42000 (91%)]\tLoss: 0.017854\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41727/42000 (99.350%)\n",
      "\n",
      "Train Epoch: 34 [6400/42000 (15%)]\tLoss: 0.003384\n",
      "Train Epoch: 34 [12800/42000 (30%)]\tLoss: 0.155915\n",
      "Train Epoch: 34 [19200/42000 (46%)]\tLoss: 0.004257\n",
      "Train Epoch: 34 [25600/42000 (61%)]\tLoss: 0.033609\n",
      "Train Epoch: 34 [32000/42000 (76%)]\tLoss: 0.057377\n",
      "Train Epoch: 34 [38400/42000 (91%)]\tLoss: 0.026612\n",
      "\n",
      "Average loss: 0.0227, Accuracy: 41720/42000 (99.333%)\n",
      "\n",
      "Train Epoch: 35 [6400/42000 (15%)]\tLoss: 0.114357\n",
      "Train Epoch: 35 [12800/42000 (30%)]\tLoss: 0.007143\n",
      "Train Epoch: 35 [19200/42000 (46%)]\tLoss: 0.050745\n",
      "Train Epoch: 35 [25600/42000 (61%)]\tLoss: 0.056336\n",
      "Train Epoch: 35 [32000/42000 (76%)]\tLoss: 0.044805\n",
      "Train Epoch: 35 [38400/42000 (91%)]\tLoss: 0.013850\n",
      "\n",
      "Average loss: 0.0211, Accuracy: 41720/42000 (99.333%)\n",
      "\n",
      "Train Epoch: 36 [6400/42000 (15%)]\tLoss: 0.033179\n",
      "Train Epoch: 36 [12800/42000 (30%)]\tLoss: 0.027404\n",
      "Train Epoch: 36 [19200/42000 (46%)]\tLoss: 0.007233\n",
      "Train Epoch: 36 [25600/42000 (61%)]\tLoss: 0.007659\n",
      "Train Epoch: 36 [32000/42000 (76%)]\tLoss: 0.054983\n",
      "Train Epoch: 36 [38400/42000 (91%)]\tLoss: 0.013036\n",
      "\n",
      "Average loss: 0.0214, Accuracy: 41725/42000 (99.345%)\n",
      "\n",
      "Train Epoch: 37 [6400/42000 (15%)]\tLoss: 0.027878\n",
      "Train Epoch: 37 [12800/42000 (30%)]\tLoss: 0.046802\n",
      "Train Epoch: 37 [19200/42000 (46%)]\tLoss: 0.027613\n",
      "Train Epoch: 37 [25600/42000 (61%)]\tLoss: 0.026644\n",
      "Train Epoch: 37 [32000/42000 (76%)]\tLoss: 0.002548\n",
      "Train Epoch: 37 [38400/42000 (91%)]\tLoss: 0.038231\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41717/42000 (99.326%)\n",
      "\n",
      "Train Epoch: 38 [6400/42000 (15%)]\tLoss: 0.002217\n",
      "Train Epoch: 38 [12800/42000 (30%)]\tLoss: 0.011092\n",
      "Train Epoch: 38 [19200/42000 (46%)]\tLoss: 0.005607\n",
      "Train Epoch: 38 [25600/42000 (61%)]\tLoss: 0.036799\n",
      "Train Epoch: 38 [32000/42000 (76%)]\tLoss: 0.008168\n",
      "Train Epoch: 38 [38400/42000 (91%)]\tLoss: 0.095509\n",
      "\n",
      "Average loss: 0.0214, Accuracy: 41726/42000 (99.348%)\n",
      "\n",
      "Train Epoch: 39 [6400/42000 (15%)]\tLoss: 0.038667\n",
      "Train Epoch: 39 [12800/42000 (30%)]\tLoss: 0.005478\n",
      "Train Epoch: 39 [19200/42000 (46%)]\tLoss: 0.029405\n",
      "Train Epoch: 39 [25600/42000 (61%)]\tLoss: 0.014730\n",
      "Train Epoch: 39 [32000/42000 (76%)]\tLoss: 0.005358\n",
      "Train Epoch: 39 [38400/42000 (91%)]\tLoss: 0.013637\n",
      "\n",
      "Average loss: 0.0214, Accuracy: 41719/42000 (99.331%)\n",
      "\n",
      "Train Epoch: 40 [6400/42000 (15%)]\tLoss: 0.055416\n",
      "Train Epoch: 40 [12800/42000 (30%)]\tLoss: 0.016057\n",
      "Train Epoch: 40 [19200/42000 (46%)]\tLoss: 0.055095\n",
      "Train Epoch: 40 [25600/42000 (61%)]\tLoss: 0.022701\n",
      "Train Epoch: 40 [32000/42000 (76%)]\tLoss: 0.020837\n",
      "Train Epoch: 40 [38400/42000 (91%)]\tLoss: 0.012839\n",
      "\n",
      "Average loss: 0.0218, Accuracy: 41713/42000 (99.317%)\n",
      "\n",
      "Train Epoch: 41 [6400/42000 (15%)]\tLoss: 0.022615\n",
      "Train Epoch: 41 [12800/42000 (30%)]\tLoss: 0.057224\n",
      "Train Epoch: 41 [19200/42000 (46%)]\tLoss: 0.067097\n",
      "Train Epoch: 41 [25600/42000 (61%)]\tLoss: 0.024828\n",
      "Train Epoch: 41 [32000/42000 (76%)]\tLoss: 0.003405\n",
      "Train Epoch: 41 [38400/42000 (91%)]\tLoss: 0.073258\n",
      "\n",
      "Average loss: 0.0206, Accuracy: 41743/42000 (99.388%)\n",
      "\n",
      "Train Epoch: 42 [6400/42000 (15%)]\tLoss: 0.013033\n",
      "Train Epoch: 42 [12800/42000 (30%)]\tLoss: 0.010868\n",
      "Train Epoch: 42 [19200/42000 (46%)]\tLoss: 0.074275\n",
      "Train Epoch: 42 [25600/42000 (61%)]\tLoss: 0.009949\n",
      "Train Epoch: 42 [32000/42000 (76%)]\tLoss: 0.009921\n",
      "Train Epoch: 42 [38400/42000 (91%)]\tLoss: 0.016493\n",
      "\n",
      "Average loss: 0.0213, Accuracy: 41715/42000 (99.321%)\n",
      "\n",
      "Train Epoch: 43 [6400/42000 (15%)]\tLoss: 0.081798\n",
      "Train Epoch: 43 [12800/42000 (30%)]\tLoss: 0.069916\n",
      "Train Epoch: 43 [19200/42000 (46%)]\tLoss: 0.044452\n",
      "Train Epoch: 43 [25600/42000 (61%)]\tLoss: 0.012287\n",
      "Train Epoch: 43 [32000/42000 (76%)]\tLoss: 0.133421\n",
      "Train Epoch: 43 [38400/42000 (91%)]\tLoss: 0.033245\n",
      "\n",
      "Average loss: 0.0217, Accuracy: 41723/42000 (99.340%)\n",
      "\n",
      "Train Epoch: 44 [6400/42000 (15%)]\tLoss: 0.019529\n",
      "Train Epoch: 44 [12800/42000 (30%)]\tLoss: 0.006364\n",
      "Train Epoch: 44 [19200/42000 (46%)]\tLoss: 0.206597\n",
      "Train Epoch: 44 [25600/42000 (61%)]\tLoss: 0.069167\n",
      "Train Epoch: 44 [32000/42000 (76%)]\tLoss: 0.005411\n",
      "Train Epoch: 44 [38400/42000 (91%)]\tLoss: 0.003269\n",
      "\n",
      "Average loss: 0.0208, Accuracy: 41723/42000 (99.340%)\n",
      "\n",
      "Train Epoch: 45 [6400/42000 (15%)]\tLoss: 0.012634\n",
      "Train Epoch: 45 [12800/42000 (30%)]\tLoss: 0.113818\n",
      "Train Epoch: 45 [19200/42000 (46%)]\tLoss: 0.059958\n",
      "Train Epoch: 45 [25600/42000 (61%)]\tLoss: 0.014339\n",
      "Train Epoch: 45 [32000/42000 (76%)]\tLoss: 0.024123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [38400/42000 (91%)]\tLoss: 0.065747\n",
      "\n",
      "Average loss: 0.0213, Accuracy: 41703/42000 (99.293%)\n",
      "\n",
      "Train Epoch: 46 [6400/42000 (15%)]\tLoss: 0.090049\n",
      "Train Epoch: 46 [12800/42000 (30%)]\tLoss: 0.133952\n",
      "Train Epoch: 46 [19200/42000 (46%)]\tLoss: 0.033584\n",
      "Train Epoch: 46 [25600/42000 (61%)]\tLoss: 0.030279\n",
      "Train Epoch: 46 [32000/42000 (76%)]\tLoss: 0.034717\n",
      "Train Epoch: 46 [38400/42000 (91%)]\tLoss: 0.060139\n",
      "\n",
      "Average loss: 0.0215, Accuracy: 41723/42000 (99.340%)\n",
      "\n",
      "Train Epoch: 47 [6400/42000 (15%)]\tLoss: 0.013381\n",
      "Train Epoch: 47 [12800/42000 (30%)]\tLoss: 0.033130\n",
      "Train Epoch: 47 [19200/42000 (46%)]\tLoss: 0.012518\n",
      "Train Epoch: 47 [25600/42000 (61%)]\tLoss: 0.140744\n",
      "Train Epoch: 47 [32000/42000 (76%)]\tLoss: 0.023351\n",
      "Train Epoch: 47 [38400/42000 (91%)]\tLoss: 0.029381\n",
      "\n",
      "Average loss: 0.0202, Accuracy: 41729/42000 (99.355%)\n",
      "\n",
      "Train Epoch: 48 [6400/42000 (15%)]\tLoss: 0.006094\n",
      "Train Epoch: 48 [12800/42000 (30%)]\tLoss: 0.045862\n",
      "Train Epoch: 48 [19200/42000 (46%)]\tLoss: 0.072814\n",
      "Train Epoch: 48 [25600/42000 (61%)]\tLoss: 0.030191\n",
      "Train Epoch: 48 [32000/42000 (76%)]\tLoss: 0.030970\n",
      "Train Epoch: 48 [38400/42000 (91%)]\tLoss: 0.007500\n",
      "\n",
      "Average loss: 0.0223, Accuracy: 41723/42000 (99.340%)\n",
      "\n",
      "Train Epoch: 49 [6400/42000 (15%)]\tLoss: 0.013639\n",
      "Train Epoch: 49 [12800/42000 (30%)]\tLoss: 0.139826\n",
      "Train Epoch: 49 [19200/42000 (46%)]\tLoss: 0.001579\n",
      "Train Epoch: 49 [25600/42000 (61%)]\tLoss: 0.028983\n",
      "Train Epoch: 49 [32000/42000 (76%)]\tLoss: 0.010276\n",
      "Train Epoch: 49 [38400/42000 (91%)]\tLoss: 0.010418\n",
      "\n",
      "Average loss: 0.0206, Accuracy: 41737/42000 (99.374%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = prediciton(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/vgg_sub5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
